import streamlit as st
import pandas as pd
import google.generativeai as genai
import psycopg2
from sqlalchemy import create_engine, text
import os
from dotenv import load_dotenv
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick

# --- 1. Configura√ß√µes Iniciais ---
st.set_page_config(layout="wide", page_title="Chat SQL de Arrecada√ß√£o")
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("Chave da API do Google n√£o encontrada.")
    st.stop()
genai.configure(api_key=api_key)

# --- 2. Conex√£o com o Banco de Dados ---
@st.cache_resource
def get_db_engine():
    try:
        db_url = "postgresql+psycopg2://user:password@postgres:5432/meubanco"
        engine = create_engine(db_url)
        with engine.connect() as connection:
            pass
        return engine
    except Exception as e:
        st.error(f"N√£o foi poss√≠vel conectar ao banco de dados: {e}")
        return None

engine = get_db_engine()
if engine is None:
    st.stop()
else:
    st.toast("üöÄ Conex√£o com o banco de dados estabelecida!")

# --- Fun√ß√£o para Carregar Nomes de Receitas ---
@st.cache_data
def carregar_df_receitas(_engine):
    try:
        with _engine.connect() as connection:
            query = "SELECT nome_receita FROM dados_mario GROUP BY nome_receita ORDER BY nome_receita;"
            return pd.read_sql_query(text(query), connection)
    except Exception as e:
        st.sidebar.error("Tabela 'dados_mario' n√£o encontrada. Recarregue os dados no PgAdmin.")
        return pd.DataFrame({'nome_receita': []})

# --- 3. Sidebar ---
st.sidebar.title("Filtros e Op√ß√µes")
df_receitas = carregar_df_receitas(engine)

receitas_selecionadas = st.sidebar.multiselect(
    label="Filtre por uma ou mais receitas",
    options=df_receitas['nome_receita'].tolist(),
    placeholder="Pesquise uma receita..."
)
with st.sidebar.expander("Ver/Pesquisar todos os nomes de receitas"):
    st.dataframe(df_receitas, use_container_width=True, hide_index=True)


# --- 4. L√≥gica do Agente LLM (Prompts Atualizados) ---
sql_table_schema = "CREATE TABLE dados_mario (ano INTEGER, mes TEXT, nome_receita TEXT, arrecadado NUMERIC);"

PROMPT_GERADOR_SQL = f"""
Voc√™ √© um especialista em PostgreSQL. Sua √∫nica tarefa √© gerar UMA CONSULTA SQL a partir da pergunta do usu√°rio.
REGRAS:
- Sua resposta DEVE SER APENAS o c√≥digo SQL puro. N√£o inclua "```sql" ou explica√ß√µes.
- Para calcular a MEDIANA da coluna 'arrecadado', use a fun√ß√£o `PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY arrecadado)`.
- Schema da Tabela `dados_mario`: {sql_table_schema}
"""

PROMPT_GERADOR_GRAFICO = """
Voc√™ √© um especialista em visualiza√ß√£o de dados com Python e matplotlib.
Sua tarefa √© EXCLUSIVAMENTE gerar um c√≥digo Python para plotar um gr√°fico a partir de um DataFrame chamado `df_resultado`.
REGRAS CR√çTICAS:
- Sua resposta DEVE SER APENAS o c√≥digo Python puro. N√ÉO inclua "```python" ou explica√ß√µes.
- O gr√°fico DEVE ser salvo como `grafico_gerado.png`.
- N√ÉO use `plt.show()`.
"""

# --- 5. Interface Principal do Chat ---
st.title("ü§ñ Chat com Banco de Dados e Gr√°ficos")
st.info("Pe√ßa totais, m√©dias, medianas e tamb√©m gr√°ficos de barras!")

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- CORRE√á√ÉO DO BUG AQUI ---
# Exibi√ß√£o do hist√≥rico com verifica√ß√£o se o arquivo de imagem existe
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message.get("query"):
            with st.expander("Ver consulta SQL"):
                st.code(message["query"], language="sql")
        if message.get("dataframe"):
            st.dataframe(pd.DataFrame(message["dataframe"]), use_container_width=True, hide_index=True)
        # S√ì TENTA EXIBIR A IMAGEM SE A CHAVE EXISTIR E O ARQUIVO TAMB√âM
        if message.get("image") and os.path.exists(message["image"]):
            st.image(message["image"])

if prompt_usuario := st.chat_input("Qual o total arrecadado por ano?"):
    st.session_state.messages.append({"role": "user", "content": prompt_usuario})
    with st.chat_message("user"):
        st.markdown(prompt_usuario)

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            try:
                # ETAPA 1: Gerar e Executar SQL
                contexto_filtro = f"Contexto de filtro: Receitas selecionadas: {receitas_selecionadas if receitas_selecionadas else 'Nenhuma'}.\n"
                prompt_sql_completo = contexto_filtro + f"Pergunta: {prompt_usuario}"

                model_sql = genai.GenerativeModel('gemini-1.5-flash', system_instruction=PROMPT_GERADOR_SQL)
                response_sql = model_sql.generate_content(prompt_sql_completo)
                sql_query = response_sql.text.strip().replace("```sql", "").replace("```", "")

                with engine.connect() as connection:
                    df_resultado = pd.read_sql_query(text(sql_query), connection)

                mensagem_resposta = f"**Resultado para:** '{prompt_usuario}'"
                if receitas_selecionadas:
                     mensagem_resposta += f"\n\n*Filtro aplicado para: {', '.join(receitas_selecionadas)}*"

                st.markdown(mensagem_resposta)
                st.dataframe(df_resultado, use_container_width=True, hide_index=True)

                msg_assistente = {
                    "role": "assistant",
                    "content": mensagem_resposta,
                    "query": sql_query,
                    "dataframe": df_resultado.to_dict('records')
                }

                # Limpa gr√°fico antigo para garantir que n√£o exibiremos um gr√°fico obsoleto
                if os.path.exists('grafico_gerado.png'):
                    os.remove('grafico_gerado.png')

                # ETAPA 2: Gerar Gr√°fico se solicitado
                palavras_chave_grafico = ['gr√°fico', 'grafico', 'plotar', 'plot', 'barras', 'visualizar', 'desenhar']
                if any(palavra in prompt_usuario.lower() for palavra in palavras_chave_grafico):
                    with st.spinner("Criando visualiza√ß√£o..."):
                        df_info_para_prompt = f"O DataFrame `df_resultado` para plotar tem as colunas: {df_resultado.columns.tolist()}. Gere o c√≥digo para o gr√°fico."
                        prompt_grafico_completo = f"{df_info_para_prompt}\n\nInstru√ß√£o: {prompt_usuario}"

                        model_grafico = genai.GenerativeModel('gemini-1.5-flash', system_instruction=PROMPT_GERADOR_GRAFICO)
                        response_grafico = model_grafico.generate_content(prompt_grafico_completo)
                        codigo_grafico = response_grafico.text.strip().replace("```python", "").replace("```", "")

                        local_scope = {"df_resultado": df_resultado, "plt": plt, "mtick": mtick}
                        exec(codigo_grafico, {}, local_scope)

                        if os.path.exists('grafico_gerado.png'):
                            st.image('grafico_gerado.png')
                            msg_assistente["image"] = 'grafico_gerado.png'

                st.session_state.messages.append(msg_assistente)

            except Exception as e:
                st.error(f"Ocorreu um erro: {e}")
                st.session_state.messages.append({"role": "assistant", "content": f"Desculpe, ocorreu um erro: {e}"})